{
    "contents" : "#' Construct basis expansion matrices.\n#'\n#' This function was created to avoid repeating it over and over in my research. The penalty for each marginal term is \\eqn{\\int \\|f''(x)\\|^2 dx}.\n#'\n#' @param df data frame for which to expand. Must already contain an intercept in column 1, and all covariates should be scaled between 0 and 1.\n#' @param num.knots a vector containing the number of knots to use for each predictor.\n#' @param bases a vector containing the bases to use for each expansion. Cubic (\\code{cr}) and cyclic (\\code{cc}) radial splines are supported.\n#' @param interactions logical: should two-way interactions (tensor products) be computed?\n#' @param knots.list optional list containing knots to use. Useful for predictions. If present, num.knots is ignored.\n#' @return A list with components:\n#' \\itemize{\n#'  \\item{\\code{C.full}}{ a matrix containing all basis expansions, with the intercept.}\n#'  \\item{\\code{partition}}{ a numeric vector corresponding to group identification. \\code{0} corresponds to the intercept.}\n#'  \\item{\\code{nvar, pc, pz, px}}{ scalars giving the number of total predictors (including 2-way interactions as individual predictors, if \\code{interactions == TRUE}),\n#'  total dimension of \\code{C.full}, and the dimensions of the linear and basis expansion terms, respectively.}\n#'  \\item{\\code{knots.list}}{ a list of knots used for expansion. Useful for creating the same basis expansion on an independent data set (for, say, validation).}\n#' }\n#' @export\n\nget_basis_expansion = function(df,\n                               num.knots,\n                               bases,\n                               interactions,\n                               knots.list = NULL){\n  #library(cluster) #for clara\n  library(mgcv) #for cyclical expansion\n\n  #df must already contain the intercept in the first column\n  n.predictors = ncol(df) - 1\n\n  if(is.null(knots.list)){\n    knots.list = list()\n    for(i in 2:(n.predictors+1)){\n      if(bases[i-1] == \"cr\"){\n        knots.list[[i-1]] = quantile(df[[i]], probs=seq(0, 1, len=num.knots[i-1]))\n      } else if(bases[i-1] == \"cc\"){\n        knots.list[[i-1]] = quantile(c(0, df[[i]], 1), probs=seq(0, 1, len=num.knots[i-1]+2))\n      } else stop(\"Bases must be cr or cc\")\n    }\n  }\n\n  # one dimensional penalty function to integrate\n  s.ij = function(indi,indj,tknots,covar){\n    ki = tknots[indi]\n    kj = tknots[indj]\n\n    36*abs((covar - ki)*(covar - kj))\n  }\n  integrand = seq(0,1,length=100) #covariates scaled to [0,1]\n\n  # get penalty matrices\n  pen.mats = list()\n  for(j in 1:length(knots.list)){\n    S.pen.cov = list() #list of penalty matrices to average\n    for(i in 1:100){ #100 of them\n      dims = num.knots[j]\n\n      tmp.mat = matrix(nrow=dims,ncol=dims)\n      for(first in 1:dims){\n        for(second in 1:dims){\n          tmp.mat[first,second] = s.ij(first,second,tknots=knots.list[[j]], covar=integrand[i])\n        }\n      }\n      S.pen.cov[[i]] = tmp.mat\n    }\n    pen.mats[[j]] = Reduce('+', S.pen.cov)/100\n  }\n\n  #compute inverse sqrts\n  OMEGA.mats = list()\n  for(i in 1:length(knots.list)){\n    OMEGA.mats[[i]] = backsolve(chol(pen.mats[[i]]), diag(num.knots[i]), transpose=T)\n  }\n\n  #get matrices\n  Z.marg.list = list()\n  for(i in 1:length(knots.list)){\n    if(bases[i]!=\"cr\" & bases[i]!=\"cc\") {\n      stop(\"Basis must be cr or cc\")\n    }\n    if(bases[i] == \"cr\"){\n      Z.marg.list[[i]] = abs(outer(df[[i+1]], knots.list[[i]], \"-\"))^3\n      Z.marg.list[[i]] = Z.marg.list[[i]] %*% OMEGA.mats[[i]]\n    } else if(bases[i] == \"cc\"){\n      tmpx = tmpy = df[[i+1]]\n      tmpdf = data.frame(\"Y\" = tmpy, \"X\" = tmpx)\n      fit.gam = mgcv::gam(Y~-1+s(X, bs=\"cc\", k=num.knots[i]+2),\n                          data=tmpdf,\n                          knots=list(\"X\" = knots.list[[i]]))\n      Z.marg.list[[i]] = mgcv::predict(fit.gam, type=\"lpmatrix\")\n      PenMat = fit.gam$smooth[[1]]$S[[1]]\n      #Z.marg.list[[i]] = Z.marg.list[[i]] %*% backsolve(chol(PenMat), diag(ncol(PenMat)), transpose=T)\n    }\n    colnames(Z.marg.list[[i]]) = rep(paste('smooth',i,sep=' '), dim(Z.marg.list[[i]])[2])\n  }\n\n  #intercept, linear terms, interaction terms\n  which.x.belongs = c(2:(n.predictors+1))\n  which.x.belongs = which.x.belongs[bases == \"cr\"]\n  X.full = as.matrix(cbind(1, df[,which.x.belongs]))\n  Z.full = cbind(Z.marg.list[[1]], Z.marg.list[[2]])\n  for(i in 3:length(Z.marg.list)){\n    Z.full = cbind(Z.full, Z.marg.list[[i]])\n  }\n\n  partition = c(0, (1:n.predictors)[bases==\"cr\"], rep(1:n.predictors, times=num.knots))\n  nvar=n.predictors\n\n  if(interactions){\n    #interactions (tensor products)\n    Z.prod.list = list() #basis expansion\n    X.prod = list() #marginal terms\n    P.list = list() #projection matrices into null space of marginals\n\n    for(i in 1:(length(knots.list)-1)){\n      Z.prod.list[[i]] = list()\n      X.prod[[i]] = list()\n      P.list[[i]] = list()\n      dim1 = ncol(Z.marg.list[[i]])\n      is.cr1 = NULL\n      if(bases[i] == \"cr\") {dim1 = dim1 + 1; is.cr1 = 1}\n\n      for(j in (i+1):length(knots.list)){\n        dim2 = ncol(Z.marg.list[[j]])\n        is.cr2 = NULL\n        if(bases[j] == \"cr\") {dim2 = dim2 + 1; is.cr2 = 1}\n\n        Z.prod.list[[i]][[j]] = matrix(ncol = (dim1)*(dim2), nrow = dim(Z.marg.list[[1]])[1])\n        X.prod[[i]][[j]] = cbind(1, is.cr1*df[[i+1]], is.cr2*df[[j+1]], Z.marg.list[[i]], Z.marg.list[[j]])\n        P.list[[i]][[j]] = X.prod[[i]][[j]] %*%\n          chol2inv(chol(crossprod(X.prod[[i]][[j]]) + diag(rep(1e-09, ncol(X.prod[[i]][[j]]))))) %*% t(X.prod[[i]][[j]])\n        #chol2inv(chol(crossprod(X.prod[[i]][[j]]))) %*% t(X.prod[[i]][[j]])\n\n        for(k in 1:dim(Z.marg.list[[1]])[1]){\n          Z.prod.list[[i]][[j]][k,] = cbind(is.cr1*df[[i+1]], Z.marg.list[[i]])[k,] %x%\n            cbind(is.cr2*df[[j+1]], Z.marg.list[[j]])[k,]\n        }\n        #do projections here\n        Z.prod.list[[i]][[j]] = (diag(dim(Z.marg.list[[1]])[1]) - P.list[[i]][[j]]) %*%\n          Z.prod.list[[i]][[j]]\n        colnames(Z.prod.list[[i]][[j]]) = rep(paste('int',i,j,sep=' '), dim(Z.prod.list[[i]][[j]])[2])\n\n      }\n    }\n\n    #unlist a level:\n    Z.prods = unlist(Z.prod.list, recursive=F)\n\n    for(i in 1:length(Z.prods)){\n      Z.full = cbind(Z.full, Z.prods[[i]])\n    }\n\n    num.knots.extra = ifelse(bases == \"cr\", num.knots+1, num.knots)\n    part.extra = outer(num.knots.extra, num.knots.extra) #number of knots for interactions\n    part.extra = part.extra*upper.tri(part.extra) #remove repeats\n    part.extra = ifelse(part.extra == 0, NA, part.extra) #remove zeros\n    part.extra = c(t(part.extra)) #make it a vector, by row\n    part.extra = part.extra[!is.na(part.extra)] #remove NAs.\n\n    partition = c(partition, rep(1:choose(n.predictors,2) + n.predictors,\n                                 times=part.extra))\n    nvar = nvar + choose(n.predictors,2)\n  }\n  C.full = as.matrix(cbind(X.full,Z.full))\n\n  #center, for effects about the mean\n  for(i in 2:dim(C.full)[2]){\n    C.full[,i] = C.full[,i] - mean(C.full[,i])\n  }\n\n  out = list(\"C.full\"=C.full,\n             \"partition\" = partition,\n             \"nvar\" = nvar,\n             \"pc\" = dim(C.full)[2],\n             \"pz\" = dim(Z.full)[2],\n             \"px\" = dim(X.full)[2],\n             \"knots\" = knots.list) #for use with predictions\n\n  return(out)\n}\n\n\n\n\n\n\n\n\n\n",
    "created" : 1446758451862.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3398074333",
    "id" : "BFB0AF7C",
    "lastKnownWriteTime" : 1446824053,
    "path" : "C:/Users/Hunter/Dropbox/My_R_Packages/hunterr/R/Basis_expansion_function.R",
    "project_path" : "R/Basis_expansion_function.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}